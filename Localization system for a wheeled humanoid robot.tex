% % % Document class
\documentclass{report}
%\documentclass{article}
% "article" = page number on title page
% "report" = no page number on title page


% % % Naming conventions
% % Cross references
% Equations - \label{e:label} \eref{e:label}
% Sections - \label{s:label} \ref{s:label}
% Subsections - \label{s:mainlabel--subsectionlabel} \ref{s:mainlabel--subsectionlabel}
% Figures - \label{f:label} \fref{label}
% % Numbering
% Sections - n * 10; n = 1, 2, ... - gives the possibility to shift other sections in between
% Equations - 
% Figures - 

% % % User packages
% % Languages
\usepackage{amsmath,amsfonts,amsthm,amssymb}
\usepackage[T1]{fontenc}
\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage[polish,german,english]{babel}
% % General
\usepackage[usenames,dvipsnames]{color}
\usepackage{extramarks}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{chngpage}
\usepackage{soul}
\usepackage[retainorgcmds]{IEEEtrantools}
\usepackage{ifthen}
\usepackage{lastpage}
\usepackage{listings}
\usepackage{cancel}
\usepackage{courier}
\usepackage{layout}
\usepackage{lscape}
\usepackage{media9}
\usepackage{multicol}
\usepackage{multimedia}
\usepackage{multirow}
\usepackage{pdflscape}
\usepackage{setspace}
\usepackage{tabularx}
\usepackage{varioref}
\usepackage{wrapfig}
\usepackage{xcolor}
\usepackage{xfrac}
\usepackage{xstring}
\usepackage{gensymb}

% % % Packages configuration
% % Tabular
\newcolumntype{Y}{>{\centering\arraybackslash}X}


% % % Command definitions
% % References
\newcommand{\bref}[1]{(\ref{#1})}
\newcommand{\cref}[1]{(\afig\ref{#1})}
%\renewcommand{\eqref}[1]{(\ref{eq:#1})}
\newcommand{\eref}[1]{(\ref{#1})}
\newcommand{\fref}[1]{(\ref{f:#1})}
\newcommand{\sref}[1]{\ref{#1}}
% % Symbols
\newcommand{\dlsh}{\reflectbox{\rotatebox[origin=c]{180}{$\Lsh$}}}
\newcommand{\drsh}{\reflectbox{\rotatebox[origin=c]{180}{$\Rsh$}}}
\newcommand\ccancel[2][black]{\renewcommand\CancelColor{\color{#1}}\cancel{#2}}
\newcommand\ccancelto[3][black]{\renewcommand\CancelColor{\color{#1}}\cancelto{#2}{#3}}
% % Font styles
\newcommand\dunderline[1]{\underline{\underline{\ #1\ }}}
\newcommand\sunderline[1]{\underline{\ #1\ }}
% % Mathematical symbols and structures
%\renewcommand{\vec}[1]{\overrightarrow{\mathbf{#1}}}
\renewcommand{\vec}[1]{\mathbf{\overline{#1}}}
% % Other
\StrLeft{\figurename}{1}[\afig]

% % Complex definitions
% Links
% Generic hyperlink -- \link[optional text]{link}
\newcommand*{\link}[2][]{
	\ifthenelse{\equal{#1}{}}
	{\href{#2}{#2}}
	{\href{#2}{#1}}}

% Http hyperlink -- \httplink[optional text]{link}
\newcommand*{\httplink}[2][]{
	\ifthenelse{\equal{#1}{}}
	{\href{http://#2}{#2}}
	{\href{http://#2}{#1}}}

% Email hyperlink -- \emaillink[optional text]{link}
\newcommand*{\emaillink}[2][]{
	\ifthenelse{\equal{#1}{}}
	{\href{mailto:#2}{#2}}
	{\href{mailto:#2}{#1}}}

% Graphics
% Inkscape path
%\IfFileExists{/dev/null}{
%	\newcommand{\Inkscape}{/usr/bin/inkscape }}{
%	\newcommand{\Inkscape}{"C:/Program Files (x86)/Inkscape/inkscape.exe" }
%}

% Include SVG-LaTeX withing scalebox
%\includesvga[0.75]{Graphics/10-odometry--right-turn}
%\includesvga[scalebox]{input-files-w/o-ext}
\newcommand{\includesvgsb}[2][1]{
%	\IfFileExists{\Inkscape}{
%		\immediate\write18{\Inkscape -z -D --file="#2.svg" --export-pdf="#2.pdf" --export-dpi=72 --export-latex}}{}
	\scalebox{#1}{\input{#2.pdf_tex}}
}

% Include SVG-LaTeX as figure
%\includesvg[0.75]{a}{Automated includesvg pdf\label{f:f4b}}
%\includesvg[scale]{input-files-w/o-ext}{caption\label{f:id}}
\newcommand{\includesvg}[3][1]{
%	\IfFileExists{\Inkscape}{
%		\immediate\write18{/home/emeres/.bin/testbell}
%		\immediate\write18{\Inkscape -z -D --file="#2.svg" --export-pdf="#2.pdf" --export-dpi=96 --export-latex}}{}
	\begin{figure}[!ht]
%		\centering
		\begin{center}
			\def\svgwidth{#1\columnwidth}
			\input{#2.pdf_tex}
			\caption{#3}
		\end{center}
	\end{figure}
}

% Scaled figure
\newcommand{\scalefig}[3]{
	\begin{figure}[!ht]
%		\centering
		\begin{center}
			\includegraphics[width=#2\columnwidth]{#1}
			\caption{#3}
		\end{center}
	\end{figure}
}

% Scaled and trimmed figure
\newcommand{\scalefigcrop}[7]{
	\begin{figure}[!ht]
%		\centering
		\begin{center}
			\includegraphics[trim=#4 #5 #6 #7, clip, width=#2\columnwidth]{#1}
			\caption{#3}
		\end{center}
	\end{figure}
}

% Script listing
\newcommand{\script}[2]
{\lstinputlisting[caption=#2,label=#1]{#1.m}}
%{\begin{itemize}\item[]\lstinputlisting[caption=#2,label=#1]{#1.m}\end{itemize}}
%{\begin{itemize}\item[]\lstinputlisting[caption=#2,label=#1]{#1.sc}\end{itemize}}
%{\label{sc:#1}\begin{itemize}\item[]\lstinputlisting[caption=#2,label=#1]{#1.sc}\end{itemize}}
%\newcommand{\script}[2]
%{\begin{itemize}\item[]\lstinputlisting[caption=#2,label={sc:#1}]{#1}\end{itemize}}

\lstloadlanguages{Matlab}
\lstset{language=Matlab,
	frame=single,	% Frame type around code
	basicstyle=\small\ttfamily,	% Basic code style
	keywordstyle=[1]\color{Blue}\bf,	% Python functions bold and blue
	keywordstyle=[2]\color{Purple},	% Python function arguments purple
	keywordstyle=[3]\color{Blue}\underbar,	% User functions underlined and blue
	identifierstyle=,	% Nothing special about identifiers
	commentstyle=\usefont{T1}{pcr}{m}{sl}\color{DarkGreen}\small,	% Comment style
	stringstyle=\color{Purple},	% String style
	showstringspaces=false,	% Space string indication
	tabsize=2,
%	escapechar={},
	breaklines=true,
	breakautoindent=false,
	prebreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\space\color{red}{\blacktriangledown}\color{blue}\thelstnumber}},
	postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\color{blue}\thelstnumber\color{red}{\blacktriangle}\space}},
	morekeywords={xlim, ylim, },	% Not default functions
	morekeywords=[2]{on, off},	% Custom function parameters
	morekeywords=[3]{FindESS},	% Custom functions
	morecomment=[l][\color{Blue}]{...},	% Line continuation (...) like blue comment
	numbers=left,
	numberfirstline=true,
	firstnumber=1,	% Line number offset
	numberstyle=\tiny\color{Blue},	% Line numbers
	stepnumber=5	% Line numbers step
}


% % % Configuration
\graphicspath{{./}{Graphics/}}
%\renewcommand{\figurename}{Wykres}
%\renewcommand{\figurename}{Figure}
%\renewcommand{\figurename}{Image}
%\renewcommand{\tablename}{Tabela}
%\renewcommand{\lstlistingname}{Skrypt}
\renewcommand{\lstlistingname}{Script}


% % % Specific Information
\newcommand{\Code}{86805}
\newcommand{\Title}{Software Architectures for Robotics}
\newcommand{\SubTitle}{Localization system for a wheeled humanoid robot}
\newcommand{\Date}{01.02.16}
\newcommand{\Time}{Wed 23:55}
\newcommand{\Recipient}{Prof. F. Mastrogiovanni, PhD C. Recchiuto}
\newcommand{\Author}{Rabbia Asghar, BEng, Ernest Skrzypczyk, BSc}


% % % Document margins
\topmargin = -0.45in
\evensidemargin = 0in
\oddsidemargin = 0in
\textwidth = 6.5in
\textheight = 9.0in
\headsep = 0.25in


% % % Setup the header and footer
\pagestyle{fancy}
\lhead{\Author}
\chead{\Code: \Title, \Recipient\\} %(\Time,\ \Date)}  %
\rhead{\firstxmark}
\lfoot{\lastxmark}
\cfoot{}
\rfoot{Page\ \thepage/\protect\pageref{LastPage}}
\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}
\setlength{\parindent}{4ex}


% % % Colors
\definecolor{DarkGreen}{rgb}{0.0,0.4,0.0}


% % % Debugging
%\tracingall


% % % % CLEAN UP
% % % Style specific commands and configuration
%\newcommand{\enterProblemHeader}[1]{\nobreak\extramarks{#1}{#1 kontynuowany na nastÄ™pnej stroniecontinued on next page\ldots}\nobreak%
%												\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak}
%\newcommand{\exitProblemHeader}[1]{\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak%
\newcommand{\enterProblemHeader}[1]{\nobreak\extramarks{#1}{#1\ldots}\nobreak%
												\nobreak\extramarks{#1 (continued)}{#1}\nobreak}
\newcommand{\exitProblemHeader}[1]{\nobreak\extramarks{#1 (continued)}{#1}\nobreak%
											  \nobreak\extramarks{#1}{}\nobreak}

\newlength{\labelLength}
\newcommand{\labelAnswer}[2]
  {\settowidth{\labelLength}{#1}
	\addtolength{\labelLength}{0.25in}
	\changetext{}{-\labelLength}{}{}{}
	\noindent\fbox{\begin{minipage}[c]{\columnwidth}#2\end{minipage}}
	\marginpar{\fbox{#1}}

	% We put the blank space above in order to make sure this
	% \marginpar gets correctly placed.
	\changetext{}{+\labelLength}{}{}{}}

\setcounter{secnumdepth}{0}
\newcommand{\ProblemName}{}
\newcounter{ProblemCounter}
\newenvironment{Problem}[1][Problem \arabic{ProblemCounter}]%
	{\stepcounter{ProblemCounter}
	\renewcommand{\ProblemName}{#1}
	\section{\ProblemName}
	\enterProblemHeader{\ProblemName}}
	{\exitProblemHeader{\ProblemName}}

\newcommand{\problemAnswer}[1]
	{\noindent\fbox{\begin{minipage}[c]{\columnwidth}#1\end{minipage}}}

\newcommand{\problemLAnswer}[1]
	{\labelAnswer{\ProblemName}{#1}}

\newcommand{\SectionName}{}
\newlength{\SectionLabelLength}{}
\newenvironment{Section}[1]%
	{ %
%
	\renewcommand{\SectionName}{#1}
	\settowidth{\SectionLabelLength}{\SectionName}
	\addtolength{\SectionLabelLength}{0.25in}
	\changetext{}{-\SectionLabelLength}{}{}{}
	\subsection{\SectionName}
	\enterProblemHeader{\ProblemName\ [\SectionName]}}
	{\enterProblemHeader{\ProblemName}

	\changetext{}{+\SectionLabelLength}{}{}{}}

\newcommand{\sectionAnswer}[1]
{

	\noindent\fbox{\begin{minipage}[c]{\columnwidth}#1\end{minipage}}
	\enterProblemHeader{\ProblemName}\exitProblemHeader{\ProblemName}
	\marginpar{\fbox{\SectionName}}

}

%% Edits the caption width
%\newcommand{\captionwidth}[1]{%
%  \dimen0=\columnwidth	\advance\dimen0 by-#1\relax
%  \divide\dimen0 by2
%  \advance\leftskip by\dimen0
%  \advance\rightskip by\dimen0
%}
% % % % CLEAN UP


% % % % CLEAN UP
% % % Title page
\title{\vspace{2in}\textmd{\textbf{\Code:\ 
\Title\ifthenelse{\equal{\SubTitle}{}}{}{\\\SubTitle}}}\\\normalsize\vspace{0.1in}\small{Date:\ 
\Time,\ \Date}\\\vspace{0.1in}\large{\textit{\Recipient}}\vspace{3in}}
\date{}
\author{\textbf{\Author}}
% % % % CLEAN UP


% % % Document
\begin{document}
\begin{spacing}{1.1}
\maketitle


% % % Table of contents
\setcounter{tocdepth}{1}
\tableofcontents
\newpage
\clearpage

% % % Text
\begin{Problem}[Rollo - Humanoid robot]
\section{Odometry}\label{s:10-odometry}
\indent\indent
Odometry is currently the most widely used technique for determining the position of a mobile robot. %TODO This would requiere a source
It mainly involves use of various encoders, for example on wheels, as sensors to estimate the robot's position relative to a starting or previous location. Usually, it is used for real-time positioning in the between the periodic absolute position measurements, for example \link[GPS (Global Positioning System)]{http://www.gps.gov/} provides absolute position feedback, however it updates at $0.1 \div 1 s$ interval, during which odometry could be used for localization. %ALT / for estimating current position
% Odometry is used to estimate position during its update interval. %REP
%The reason for its popularity is it's simplicity and the straight forward approach ot its implementation. However, this comes at a cost
One of the major downsides of odometry is its sensitivity to errors. There are various error sources discussed in section \nameref{s:10-odometry--errors} \vpageref{s:10-odometry--errors} in detail. One significant source of error influencing the accuracy of odometry that is worth mentioning however, is the integration of velocity measurements over time to give position estimates.

First the odometry based motion model for the robot will be derived.

The model is derived based on the following important assumptions:

\begin{enumerate}
	\item The robot is a rigid body
	\item The model represents a differential drive robot
	\item The wheels of the robot are perfect discs and have the same diameters
	\item the wheels have no thickness
	\item There is no slip in the wheels
	\item Both wheels are turning in the forward direction
\end{enumerate} 

A differential drive robot runs straight when the linear speed of both the left and right wheel is same. If the speed of one wheel is greater than the other, the robot runs in an arc. This derivation can be divided in three distinct cases of robot motion:

The basic premise for the odometry model of the Rollo humanoid robot is presented in figures \fref{10-odometry-rt-2w} and \fref{10-odometry-lt-4w}.

%\includesvg[0.75]{Graphics/10-odometry--left-turn}{Odometry model with the simplified 2 wheel configuration for the right turn.\label{f:10-odometry-lt-2w}}
\includesvg[0.75]{Graphics/10-odometry--right-turn}{Odometry model with the simplified 2 wheel configuration for the right turn.\label{f:10-odometry-rt-2w}}

%\includesvg[0.75]{Graphics/10-odometry--right-turn--4-wheels}{Odometry model with the simplified 4 wheel configuration for the right turn.\label{f:10-odometry-rt-4w}}
\includesvg[0.75]{Graphics/10-odometry--left-turn--4-wheels}{Odometry model with the simplified 4 wheel configuration for the left turn.\label{f:10-odometry-lt-4w}}

\begin{enumerate}
	\item Clockwise direction
	\item Counterclockwise direction
	\item Straight line
\end{enumerate}

\subsection{Clockwise direction}\label{s:10-odometry--cw}

First, the case is considered when the speed of left wheel is greater than the right, and the robot will run in clockwise direction. Both right and left wheel will rotate around the same center of a circle. %TODO How about making the origin of the circles in the drawings and refer to them?

$P_i$ represents the initial position of the robot, defined by the center of the line joining two wheels, while $l$ represents wheel base, ergo distance between two wheels. $S_L$ and $S_R$ represent the distance travelled by left and right wheel respectively.
$\Delta\Theta$ represents the angle of travel for both the wheels and $r$ is the radius of travel from the center of robot. 
With encoder feedback from left and right wheel, $S_L$ and $S_R$ can simply be computed using equations \eref{e:SL} and \eref{e:SR}

\begin{equation}\label{e:SL}
	S_L = \frac{n_L}{60} 2 \pi r_L
\end{equation}

\begin{equation}\label{e:SR}
	S_R = \frac{n_R}{60} 2 \pi r_R
\end{equation}

where $n_L$ and $n_R$ are the revolutions per minute ([rpm]) of left and right wheel, and $r_L$ and $r_R$ are the radii of the 2 wheels. %TODO legend instead of essay on meaning?

$S_L$ and $S_R$ can be related to $r$ and $\Delta\Theta$ using formulas \eref{e:SL=rtheta} and \eref{e:SR=rtheta}

\begin{equation}\label{e:SL=rtheta}
	S_L = (r + \frac{l}{2}) \Delta\Theta
\end{equation}

\begin{equation}\label{e:SR=rtheta}
	S_R = (r - \frac{l}{2}) \Delta\Theta 
\end{equation}

The equations \eref{e:SL=rtheta} and \eref{e:SR=rtheta} \vpageref[above] can be solved simultaneously to compute $\Delta\Theta$. % and $l$.


%\begin{equation}\label{e:r}
%	r  = \frac{l}{2} \cdot \frac{S_L + S_R}{S_L - S_R} % Travel distance
%\end{equation}

\begin{equation}\label{e:thetaCW}
	\Delta\Theta = \frac{S_L - S_R}{l} % Travel angle
\end{equation}

The length between initial position, $P_i$ and final position, $P_f$ can be approximated by taking average of $S_L$ and $S_R$.

\begin{equation}\label{e:delS}
	\Delta S = \frac{S_L + S_R}{2} % del S 
\end{equation}


Final position of the robot and its orientation can then be derived using basic trigonometry and geometry relations as displayed in equation \eref{e:P_fCW}. In general this length [FIG] is approximated to dels S for a very small step of time. %%FIG


\begin{IEEEeqnarray}{CCC}\label{e:P_fCW}
	P_f  & = & 
	\begin{bmatrix}
		P_{ix} + \Delta S ( \cos(\Theta_i - \frac{\Delta\Theta}{2}) ), & P_{iy} + \Delta S ( \sin(\Theta_i - \frac{\Delta\Theta}{2}) 
	\end{bmatrix}
\end{IEEEeqnarray}

\begin{equation*}\label{e:finalorientationCW}
	\mathrm{\Theta_f = \Theta_i - \Delta\Theta}\nonumber
\end{equation*}

where $\Theta_f$ and $\Theta_i$ are the final and initial orientation respectively.

\subsection{Counterclockwise direction}\label{s:10-odometry--ccw}
Similar derivation of the robot can be derived for counterclockwise rotation, when the rpm of right wheel is higher than that of the left wheel. 

\begin{equation}\label{e:thetaCCW}
\Delta\Theta = \frac{S_R - S_L}{l} % Travel angle
\end{equation}

The relations for final position and rotation are as follows for this case:

\begin{IEEEeqnarray}{CCC}\label{e:P_fCCW}
	P_f  & = & 
	\begin{bmatrix}
		P_{ix} + \Delta S ( \cos(\Theta_i + \frac{\Delta\Theta}{2}) ), & P_{iy} + \Delta S ( \sin(\Theta_i + \frac{\Delta\Theta}{2}) 
	\end{bmatrix}\end{IEEEeqnarray}

\begin{equation*}\label{e:finalorientationCCW}
	\mathrm{\Theta_f = \Theta_i + \Delta\Theta}\nonumber
\end{equation*}

where $\Theta_f$ and $\Theta_i$ are the final and initial orientation respectively.

\subsection{Straight line motion}\label{s:10-odometry--straight-line-motion}

In case of straight line motion, the orientation of the robot stays the same. Thus, $\Theta$ is this case is 0. Also, $S_L$ is the same as $S_R$.


\begin{IEEEeqnarray}{CCC} \label{e:P_fSt}
	P_f  & = & 
	\begin{bmatrix}
		P_{ix} + S_L( \cos(\Theta_i) ), & P_{iy} + S_L \sin(\Theta_i)
	\end{bmatrix}
\end{IEEEeqnarray}

\begin{equation*}\label{e:finalorientationSt}
	\mathrm{\Theta_f = \Theta_i }\nonumber
\end{equation*}

\subsection{Final set of equations}\label{s:10-odometry--finaleq}
With the derivation of formulas understood for all three cases,for the ease of computation it is desirable to have the same set of equations in all cases.

The equations selected for this model are selected as follows.

\begin{equation}\label{e:thetaCWfinal}
\Delta\Theta = \frac{S_L - S_R}{l} % Travel angle
\end{equation}

\begin{equation}\label{e:delSfinal}
\Delta S = \frac{S_L + S_R}{2} % del S 
\end{equation}

\begin{IEEEeqnarray}{CCC}\label{e:P_fCWfinal}
	P_f  & = & 
	\begin{bmatrix}
		P_{ix} + \Delta S ( \cos(\Theta_i - \frac{\Delta\Theta}{2}) ), & P_{iy} + \Delta S ( \sin(\Theta_i - \frac{\Delta\Theta}{2}) 
	\end{bmatrix}
\end{IEEEeqnarray}

\begin{equation}\label{e:finalorientationCWfinal}
\mathrm{\Theta_f = \Theta_i - \Delta\Theta}\nonumber
\end{equation}


\subsection{Adaption of odometry model for Rollo}\label{s:10-odometry--rollo}
\indent\indent

Currently, the encoders feedback is unavailable in the robot and true odometry model can not be implemented.
However, an attempt has been made to implement its modified version.
The distance covered by right and left wheels is instead estimated from the control command.


Rollo was run in a straight line at different commands and its location feedback from the motion capture system was logged. For a certain command, average speed of left and right wheel was determined from the logs. The logs were then analyzed using Matlab as follows.

\begin{enumerate}
	\item The position x and y of the robot was plotted and line of best fit was plotted for the data set.
	\item For the displacement of the robot, total distance traveled by the robot and change in orientation was determined using the line of best fit.
	\item Using the timestamps in the logs, distance traveled and the change in orientation was determined for unit time. 
	\item The rpm of the wheels was determined using the relation in equations \eref{e:SL} through \eref{e:delS}.
\end{enumerate}

The above procedure is based on the assumption that there was no linear acceleration at a given velocity command and the rate of change of robot's orientation was constant.

The procedure was repeated for clockwise and counterclockwise rotation of the robot.


%\subsubsection{Straight line motion}\label{s:10-odometry--rollo--straight-line-motion}
\subsubsection{Few challenges in the modeling of Rollo}
\begin{enumerate}
	\item Because of the mechanical difference in the two legs, it is almost impossible for the two wheels to run at same speed . Moreover, the two motors/wheels are powered using 2 different battery packs and are run in open loop. The difference in voltage level further results in different speed of the motor at the same pwm. This is a major source for deviation in behavior of robot's adjusted odometry model.

	\item One of the Rollo's wheels is visibly skewed.
	
	\item more? % TODO
\end{enumerate}

\subsection{Odometry errors}\label{s:10-odometry--errors} %TODO refine the whole subsection, define systematic and random errors, shows the differences and the influence on the overall error
\indent\indent
As briefly discussed above, odometry is very sensitive to errors. Results of an odometry based models can be improved by rapid and accurate data collection, equipment calibration, and processing. 

The sources of odometry errors can be broadly divided into two categories.
\begin{enumerate}
	\item Systematic errors
	\item Non-systematic errors
\end{enumerate}

\subsubsection{Systematic errors}
Systematic errors are caused by inherent properties of the system. They are usually caused by imperfections in the design and mechanical implementation of a mobile robot.  On most smooth indoor surfaces, systematic errors play a much bigger role in odometry errors than non-systematic errors.Also, systematic errors accumulate constantly.

The major sources of the systematic error in an odometry model of a robot are unequal wheel diameters and the uncertainty about the effective wheelbase.

Rollo consists of 4 rubber tires, 2 on each side. Rubber tires help improve traction but they are difficult to manufacture to exactly the same diameter. Also, with time, rubber tires compress differently under asymmetric load distribution. The diameters are used in computing $S_L$ and $S_R$ as previously shown in equations \eref{e:SL} and \eref{e:SR}.

Furthermore, the contact area between the tires of Rollo and the floor is very wide. This gives trouble in determining the wheelbase of the robot. Wheel base is used in computation of angle of travel as previously shown in equations \eref{e:thetaCW}.

%TODO include this
The errors can be divided into systematic and random. 
Three main sources of systematic errors in odometry:
\begin{itemize}
	\item Distance
	\item Rotation
	\item Skew
\end{itemize}

Last two more significant with time.
%TODO

Other Examples of sources of these errors include
\begin{enumerate}
	\item Average of both wheel diameters differ from nominal diameter
	\item Misalignment of wheels
	\item Limited resolution during integration (encoder sampling rate, encoder measurement resolution)
\end{enumerate}


\subsubsection{Non-systematic errors}
Non-systematic errors are caused by unknown and unpredictable changes in the system or in the environmental conditions.
In mobile robots, they are usually caused by uneven floors. On rough surfaces with significant irregularities, non-systematic errors may be more dominant. On contrary to systematic errors, non-systematic errors do not accumulate with time.

Some examples of non-systematic errors are as follows:
\begin{enumerate}
	\item Travel over uneven floors or unexpected objects on the floor
	\item Wheel-slippage due to:
	\begin{enumerate}
		\item slippery floors
		\item over-acceleration
		\item fast turning (skidding)
		\item non-point wheel contact with the floor
	\end{enumerate}
	
\end{enumerate}

%The errors can be divided into systematic and random. 
%Three main sources of systematic errors in odometry:
%\begin{itemize}
%	\item Distance
%	\item Rotation
%	\item Skew
%\end{itemize}

%Last two more significant with time.

\subsection{Measuring Odometry Errors}

University of Michigan Benchmark test (UMBmark) procedure was planned to measure odometry errors and calibrate the system.This procedure was developed by Johann Borenstein and Liqiang Feng around 1995 in the University of Michiganâ€™s Advanced Technologies Lab.  Details of this test can be found in the research paper.

As discussed in the previous section, there are 2 dominant sources of systematic errors in odometry: unequal wheel diameters and the uncertainty about the effective wheelbase.

Unfortunately, we are estimating $S_L$ and $S_R$ from the command given to the robot due to unavailability of encoder feedback. 
%That means equations \eref{e:SL} and \eref{e:SR} are not used in the modified model. 
Even if we are able to determine the error in the relative size of the wheels and error due to the uncertainty in effective wheelbase, they can not be corrected or calibrated in the current model. However, the details of the procedure to determine effective wheelbase is described in this section.

An incorrect wheelbase value will result in incorrect computation of angle of travel, $\Delta\theta$ refer to \eref{e:thetaCWfinal}.

This error, $E_b$ is directly proportional to the effective wheelbase divided by the nominal wheelbase, $l$ :

\begin{equation}\label{e:E_b}
E_b = \frac{effective wheelbase}{l}
\end{equation}

After computing this error, we can replace the nominal wheelbase in equation \eref{e:thetaCWfinal} by effective wheelbase.
so we can correct for this error by multiplying the nominal wheelbase (bn) by the error factor to give us the effective wheelbase (be):

\begin{equation}\label{e:thetacalibrated}
\Delta\Theta = \frac{S_L - S_R}{E_b*l} % Travel angle
\end{equation}


$E_b$ is determined using UMBmark procedure. The summary of the UMBmark setup for Rollo is as follows:

%The summary of the UMBmark setup for measuring odometry errors in Rollo is as follows:
\begin{enumerate}
	\item 	At the beginning of the run, measure the absolute position and orientation of the robot using  motion capture system and initialize to that position the starting point of the vehicle's odometry program.
	\item Run the vehicle through a 2Ã—2 m square path in cw direction, making sure to
	\begin{enumerate}
		\item stop after each 2 m straight leg;
		\item make a total of four 90 -turns on the spot;
		\item run the vehicle slowly to avoid slippage.
	\end{enumerate}
	\item Upon return to the starting area, measure the absolute position and orientation of the robot using  motion capture system
	\item Compare the absolute position to the robot's calculated position using equations \eref{e:x_error}, \eref{e:y_error} and \eref{e:orienation_error}.

\begin{equation}\label{e:x_error}
\epsilon x = x_abs - x_calc
\end{equation}
	
\begin{equation}\label{e:y_error}
\epsilon y = y_abs - y_calc
\end{equation}

\begin{equation}\label{e:orienation_error}
\epsilon \theta = \theta_abs - \theta_calc
\end{equation}	

	\item Repeat steps 1-4 for four more times (i.e., a total of five runs).
	\item Repeat steps 1-5 in ccw direction.
	\item Compute coordinates of center of gravity for each cluster in cw and ccw direction using equations \eref{e:cog_x} and \eref{e:cog_y}  where n is 5.

\begin{equation}\label{e:cog_x}
x_{c.g.,cw/ccw} = \frac{1}{n}\sum_{i=1}^{n} \epsilon x_{i,cw/ccw} 
\end{equation}

\begin{equation}\label{e:cog_y}
y_{c.g.,cw/ccw} = \frac{1}{n}\sum_{i=1}^{n} \epsilon y_{i,cw/ccw}
\end{equation}
	\item Compute $E_b$ using equations \eref{e:E_b_alpha},\eref{e:alpha_x} and \eref{e:alpha_y}

%	\item Use Eqs. (2) and (3) to express the experimental results quantitatively as the measure of odometric accuracy for systematic errors, Emax,syst.

%	\item If an estimate for the vehicleâ€™s susceptibility to non-systematic errors is needed, then perform steps 1-6 again, this time placing a round
%	10 mm diameter object (for example, an electrical household cable) under the inside wheel of the robot. The object must be placed there	10 times, during the first leg of the square path.
%	\item Compute the average absolute orientation error
\end{enumerate}




\begin{equation}\label{e:E_b_alpha}
E_b = \frac{90\degree}{90\degree - \alpha}
\end{equation}

where $\alpha$ can be computed as 
\begin{equation}\label{e:alpha_x}
\alpha =  \frac{x_{c.g.,cw} + x_{c.g.,ccw}}{-4L} \frac{180\degree}{\pi}
\end{equation}

or
\begin{equation}\label{e:alpha_y}
\alpha =  \frac{y_{c.g.,cw} - y_{c.g.,ccw}}{-4L} \frac{180\degree}{\pi}
\end{equation}

and L represents the side of square  pathi.i.e. 2m.

\section{System and Measurements Model}\label{s:20-Model}
\indent\indent
\subsection{System Model}\label{s:20-Model--SysModel}
In order to implement Kalman Filter, the previously described model must be first represented in state space representation.

We can define the location of the robot at instant $k$ using state variables. This will include position in x and y coordinates and orientation.
\begin{IEEEeqnarray}{CCCCCCCCC} \label{eq:xk localistion}
	x_k & = & 
	\begin{bmatrix}
		x_{[x],k}\\
		x_{[y],k}\\
		x_{[\theta],k}\\
	\end{bmatrix}
\end{IEEEeqnarray}

The control input provided to robot is the speed of right and left wheel. This defines the distance covered by both the wheels in unit time. The relative displacement of the robot at instant $k$ can be notated by $d_k$. Using equations \eref{e:P_fCCW},\eref{e:P_fCW} and \eref{e:P_fSt}, relative displacement can be expressed in terms of $\Delta S$ and $\theta$. Thus, control input $u_k$ can be expressed as a function of relative displacement.

\begin{equation} \label{eq:uk displacmenet}
	u_k  =  j(d_k)
\end{equation}
% 
\begin{IEEEeqnarray*}{CCCCCCCCC} \label{eq:uk displacement2}
	u_k & = & 
		\begin{bmatrix}
			u_{[\Delta S],k}\\
			u_{[\Delta \theta],k}\\
		\end{bmatrix}
\end{IEEEeqnarray*} 
 
Given $x_{k-1}$ and $u_{k-1}$, the next location of the robot, $x_k$ can be computed.  
\begin{IEEEeqnarray}{CCCCCCCCC} \label{eq:xk function}
	x_k & = & f(x_{k-1}, u_{k-1}) & = & 
	\begin{bmatrix}
		f_x(x_{k-1}, u_{k-1})\\
		f_y(x_{k-1}, u_{k-1})\\
		f_\theta(x_{k-1}, u_{k-1})\\
	\end{bmatrix}
\end{IEEEeqnarray} 

In the above derivation of the system model it was assumed that there are no noise sources. In the next section, we model the noise in the system.

\subsection{System Model with noise}\label{s:20-Model--SysModeNoisel}
First, we will add noise to the relative displacement with the assumption that it can be modeled by a random noise vector $q_k$ such that the noise is Gaussian distribution with zero mean,$\hat{q_k}$ and covariance matrix,$U_k$.

\begin{equation} \label{eq: Noise Model}
q_k \sim   N(\hat{q_k} , U_k) 
\end{equation}

where

\begin{IEEEeqnarray*}{CCCCCCCCC} \label{eq:qk mean}
	\hat{q_k} & = & 
	\begin{bmatrix}
		0\\
		0\\
	\end{bmatrix}
\end{IEEEeqnarray*} 

and 

\begin{equation*} \label{eq: Uk}
	U_k = \mathrm{E}(q_k - \hat{q_k}) (q_k - \hat{q_k})^T  
	\end{equation*}


\begin{IEEEeqnarray*}{CCCCCCCCC} \label{eq:Uk covariance}
	U_k & = &  
	\begin{bmatrix}
		{\sigma}^2_{q[\Delta S],k} & {\sigma}_{q[\Delta\theta],k} {\sigma}_{q[\Delta S],k}\\
		{\sigma}_{q[\Delta\theta],k} {\sigma}_{q[\Delta S],k} & {\sigma}^2_{q[\Delta\theta],k}\\
	\end{bmatrix}
\end{IEEEeqnarray*} 

With the assumption that the noise sources are independent, the off-diagonal elements of the covariance matrix, $U_k$ are equal to zero.The computation of variances $ {\sigma}^2_{q[\Delta S],k}  $ and ${\sigma}^2_{q[\theta],k} $ for the model is discussed in section.
 
 The control input, or relative displacement can be expressed now as shown below.
\begin{equation} \label{eq: Uk + noise}
u_k = j(d_k) + q_k  
\end{equation}

\begin{IEEEeqnarray*}{CCCCCCCCC} \label{eq:Uk + noise2}
	u_k & = & 
	\begin{bmatrix}
			u_{[\Delta S],k}\\
			u_{[\Delta \theta],k}\\
	\end{bmatrix}
	& + &
	\begin{bmatrix}
			q_{[\Delta S],k}\\
			q_{[\Delta \theta],k}\\
	\end{bmatrix}	
\end{IEEEeqnarray*} 

This makes $u_k$ a random vector. Assuming, that $u_{[\Delta S],k}$ and $u_{[ \theta],k}$ are deterministic, uncertainty in$ u_k $equals the uncertainty in the noise term $q_k$.

The system noise can similarly be modeled by a random noise vector $w_k$ such that the noise is Gaussian distribution with zero mean , $\hat{w_k}$ and covariance matrix, $Q_k$.

%TODO
This noise source is not directly related to the relative displacement but is inherent to the system.???
%TODO

\begin{equation} \label{eq: Noise Model w_k}
w_k \sim   N(\hat{w_k} , Q_k) 
\end{equation}

where

\begin{IEEEeqnarray*}{CCCCCCCCC} \label{eq:wk mean}
	\hat{w_k} & = & 
	\begin{bmatrix}
		0\\
		0\\
		0\\
	\end{bmatrix}
\end{IEEEeqnarray*} 

and 

\begin{equation*} \label{eq: Qk}
Q_k = \mathrm{E}(w_k - \hat{w_k}) (w_k - \hat{w_k})^T  
\end{equation*}


\begin{IEEEeqnarray*}{CCCCCCCCC} \label{eq:Qk covariance}
	Q_k & = &  
	\begin{bmatrix}
		{\sigma}^2_{w[x],k} & {\sigma}_{w[y],k} {\sigma}_{w[x],k} &  {\sigma}_{w[\theta],k} {\sigma}_{w[x],k}\\
		{\sigma}_{w[x],k} {\sigma}_{w[y],k} & {\sigma}^2_{w[y],k} & {\sigma}_{w[\theta],k} {\sigma}_{w[y],k}\\
		{\sigma}_{w[x],k} {\sigma}_{w[\theta],k} & {\sigma}_{w[\theta],k} {\sigma}_{w[x],k} & {\sigma}^2_{w[\theta],k}\\
	\end{bmatrix}
\end{IEEEeqnarray*} 

With the assumption that the noise sources are independent, the off-diagonal elements of the covariance matrix, $Q_k$ are equal to zero.The computation of variances $ {\sigma}^2_{w[x],k}  $ , $ {\sigma}^2_{w[y],k}  $ and ${\sigma}^2_{w[\theta],k} $ for the model is discussed in section.

 The system can be expressed now as shown below.
 \begin{equation} \label{eq: xk + wk}
	x_k = f(x_{k-1}, u_{k-1}) + w_k 
 \end{equation}
 
\begin{IEEEeqnarray}{CCCCCCCCC} \label{eq:xk + noise function}
	x_k & = & 
	\begin{bmatrix}
		f_x(x_{k-1}, u_{k-1})\\
		f_y(x_{k-1}, u_{k-1})\\
		f_\theta(x_{k-1}, u_{k-1})\\
	\end{bmatrix}
	& + &
	\begin{bmatrix}
		w_{[x],k-1})\\
		w_{[y],k-1})\\
		w_{[\theta],k-1})\\
	\end{bmatrix}	
\end{IEEEeqnarray} 

$w_k$ consists of noise sources that are not directly related to $u_k$.
Now, $x_k$ is a random vector and with every time step the system noise increases the variance. Thus, the variance of the location grows with every time step. %assuming that $f_x$, $f_y$ and $f_\theta$ are deterministic, 
 
We have proposed the System Model so that we can implement Kalman Filter on it. Now, we need to prepare the Measurement Model for it.


\subsection{Measurement Model with noise}\label{s:20-Model--MeasurementModel}
Starting with the assumption that there is no noise in the measurement, $z_k$, it is simply a vector containing for each state variable a variable that takes on the value of the corresponding state variable.
The measurement vector, $z_k$ is 

\begin{IEEEeqnarray}{CCCCCCCCC} \label{eq:zk}
	z_k & = & 
	\begin{bmatrix}
		z_{[x],k}\\
		z_{[y],k}\\
		z_{[\theta],k}\\ 	
	\end{bmatrix}
\end{IEEEeqnarray} 


In our system, we use the motion capture system in the lab to localize the robot. The motion capture system acts as absolute sensor and provides us directly the position of the robot in x and y coordinates and its orientation. Thus, $z_k$ in this case is simply expressed as \eref{eq:zk 2}

\begin{IEEEeqnarray*}{CCCCCCCCC} \label{eq:zk 2}
	z_k & = & 
	\begin{bmatrix}
		x_{[x],k}\\
		x_{[y],k}\\
		x_{[\theta],k}\\ 	
	\end{bmatrix}
\end{IEEEeqnarray*} 


Now, we can add noise to the measurement model. We assume that the noise in the odometry can be modeled by a random noise vector $v_k$ such that the noise is Gaussian distribution with zero mean,$\hat{v_k}$ and covariance matrix,$R_k$ .

\begin{equation} \label{eq: Noise Model vk}
v_k \sim   N(\hat{v_k} , R_k) 
\end{equation}

where

\begin{IEEEeqnarray*}{CCCCCCCCC} \label{eq:vk mean}
	\hat{v_k} & = & 
	\begin{bmatrix}
		0\\
		0\\
		0\\
	\end{bmatrix}
\end{IEEEeqnarray*} 

and 

\begin{equation*} \label{eq: Rk}
R_k = \mathrm{E}(v_k - \hat{v_k}) (v_k - \hat{v_k})^T  
\end{equation*}

%
\begin{IEEEeqnarray*}{CCCCCCCCC} \label{eq:Rk covariance}
	R_k & = &  
	\begin{bmatrix}
		{\sigma}^2_{v[x],k} & {\sigma}_{v[y],k} {\sigma}_{v[x],k} &  {\sigma}_{v[\theta],k} {\sigma}_{v[x],k}\\
		{\sigma}_{v[x],k} {\sigma}_{v[y],k} & {\sigma}^2_{v[y],k} & {\sigma}_{v[\theta],k} {\sigma}_{v[y],k}\\
		{\sigma}_{v[x],k} {\sigma}_{v[\theta],k} & {\sigma}_{v[\theta],k} {\sigma}_{v[x],k} & {\sigma}^2_{v[\theta],k}\\
	\end{bmatrix}
\end{IEEEeqnarray*} 

With the assumption that the noise sources are independent, the off-diagonal elements of the covariance matrix, $R_k$ are equal to zero.

The measurement model can be expressed now as shown below.
\begin{equation} \label{eq: zk + noise}
z_k = x_k + v_k  
\end{equation}

\begin{IEEEeqnarray*}{CCCCCCCCC} \label{eq:Uk + noise2}
	z_k & = & 
	\begin{bmatrix}
		x_{[x],k}\\
		x_{[y],k}\\
		x_{[\theta],k}\\ 
	\end{bmatrix}
	& + &
	\begin{bmatrix}
		v_{[x],k-1})\\
		v_{[y],k-1})\\
		v_{[\theta],k-1})\\
	\end{bmatrix}	
\end{IEEEeqnarray*} 

Since the measurement noise $v_k$ is a Gaussian vector, this makes $z_k$ a random vector.


\section{Kalman Filter}
\indent\indent

Kalman filter is an algorithm that uses a series of measurements observed over time, containing statistical noise and other inaccuracies, and produces estimates of unknown variables that tend to be more precise than those based on a single measurement alone.(WIKI REFERENCE).
%TODO
Provide an actual link, and not only to the wikipage, to the actual source
%TODO

A physical system is driven by a set of external inputs or controls and its outputs are evaluated by sensors, such that the knowledge on the systemâ€™s behavior is solely given by the inputs and the observed outputs. For example, in our case, the physical system is a mobile robot and we are given the problem of localizing it. The control or the input is defined by the velocity command given to the right and left wheel which determines the relative displacement of the robot. The observed output is its position and orientation measured from Optitack  motion capture system. The observations convey the errors and uncertainties in the process, namely the sensor noise and the system errors. Based on the available information (control inputs and observations), Kalman filter computes an estimate of the systemâ€™s state by minimizing the variance of the estimation error. From a theoretical standpoint, the main assumption of the Kalman filter is that the underlying system is a linear dynamical system and that all error terms and measurements have a Gaussian distribution.  

Kalman Filtering is a recursive analytical technique involving 2 main steps: prediction and innovation.
Prediction is also known as 'Time update' and refers to prediction of state variables using previous state and control input. This step does not involve using measurement.
Innovation which is also known as 'Correction' or 'Measurement update' refers to estimation of state variable using measurement.


Kalman filter is popularly used in the localization of the robot because of its efficiency and accuracy. Some of its characteristics are as follows:

\begin{enumerate}
	\item Computationally efficient, update filter when adding new measurements to the existing data set
	\item Very simple to implement
	\item Uncertainty estimates are provided as part of the filter
	\item Recursive Algorithm, that means it can be implemented in real time using only the present input measurements and the previously calculated state.
\end{enumerate}


 All members of kalman family of filters e.g. extended kalman filter and unscented kalman filter comply with a structured sequence of six steps per iteration The six steps are listed as follows.

\begin{enumerate}
	\item \textbf{State estimate time update:} An updated state prediction $\hat{x}_{k|k-1}$ is made, based on a priori information and the system model.
	\item \textbf{Error covariance time update:} The second step is to determine the predicted state-estimate error covariance matrix, $\Sigma_{k|k-1}$ based on a priori information and the system model
	\item \textbf{Estimate system output:} The third step is to estimate the systemâ€™s output, $\hat{z}_{k} $ corresponding to the timestamp of the most recently received measurement using present a priori information.
	\item \textbf{Estimator gain matrix:} The fourth step is to compute the estimator gain matrix,$H_k$.
	\item \textbf{State estimate measurement update:} The fifth step is to compute the a posteriori state estimate, $\hat{x}_{k|k}$ by updating the a priori estimate using the estimator gain and the output prediction error.
	\item \textbf{Error covariance measurement update:} The final step computes the a posteriori error covariance matrix, $\Sigma_{k|k}$.
	\end{enumerate}
	
	
	

\subsection{Kalman Filter Equations For Linear System }
In order to implement Kalman Filter, we first represent our linear system as follows.

\begin{align}
x_{k+1} &= Ax_{k} + Bu_{k} + w_{k}\notag\\
z_{k} &= Cx_{k} + v_{k}
\label{eqn:system}
\end{align}
where $w_{k} \sim N\left(0,Q_k\right)$ and  $v_{k} \sim
N\left(0,R_k\right)$.

%, and $x_{0} \sim
%N\left(x_{0|-1},P_{0|-1}\right)$.
%
We will proceed with the assumption that A, B, C, Q and R are constant for our system.
Given initial state estimate, $\hat{x}_{0|0}$ and initial state covariance matrix, $\Sigma_{0|0}$ the Kalman Filter can be computed using following set of equations.

\subsubsection{Prediction or Time update:}
\begin{align}
\hat{x}_{k|k-1} &=  A\hat{x}_{k-1|k-1} + Bu_{k-1}\notag\\
\Sigma_{k|k-1} &= A \Sigma_{k-1|k-1} A^T + Q
\label{eqn:predictionLinear}
\end{align}

\subsubsection{Innovation or Measurement update:}
\begin{align}
H_k &=  \Sigma_{k|k-1} C^T {(C \Sigma_{k|k-1} C^T + R)}^{-1}\notag\\
\hat{x}_{k|k} &=  \hat{x}_{k|k-1} + H_k [z_{k} - C\hat{x}_{k|k-1}]\notag\\
\Sigma_{k|k} &= [I - H_k C]\Sigma_{k|k-1}
\label{eqn:innovationLinear}
\end{align}


%
% Note that $x \sim
% N\left(\mu,\Sigma\right)$ means
%\begin{equation}
%P\left(x\right) = \frac{1}{\left(2\pi\right){|\Sigma|}^{1/2}} e^{-\frac{1}{2}\left(x-\mu\right)\trans\Sigma^{-1}\left(x-\mu\right)}.\notag
%\end{equation}
%We also have: $Ex = \mu$ and $E\left(x-\mu\right)\left(x-\mu\right)\trans = \Sigma$.
%
%
%We will use the following notation:
%\begin{align}
%\hat{x}_{t|t} &= E\left[x_{t}|y_{0\colon t}\right]\notag\\
%P_{t|t} &= E\left[\left(x_{t} - \hat{x}_{t|t}\right)\left(x_{t} - \hat{x}_{t|t}\right)\trans|y_{0\colon t}\right]\notag\\
%\hat{x}_{t+1|t} &= E\left[x_{t+1}|y_{0\colon t}\right]\notag\\
%P_{t+1|t} &= E\left[\left(x_{t+1} - \hat{x}_{t+1|t}\right)\left(x_{t+1} - \hat{x}_{t+1|t}\right)\trans|y_{0\colon t}\right]\notag
%\end{align}
%
%%Note that because $x_{t|\cdot}$ is a Gaussian random variable, it is
%sufficient to only keep track of the mean and covariance.  We can do
%so by the following computations at each time $t$:
%\begin{align}
%\hat{x}_{t+1|t} &= A\hat{x}_{t|t} + Bu_{t}\notag\\
%P_{t+1|t} &= AP_{t|t}A\trans +\Sigma_{w}\notag\\
%\hat{x}_{t+1|t+1} &= \hat{x}_{t+1|t} + K_{t+1}\left(y_{t+1}-C\hat{x}_{t+1|t}\right)\notag\\
%K_{t+1} &= P_{t+1|t}C\trans\left(CP_{t+1|t}C\trans + \Sigma_{v}\right)^{-1}\notag\\
%P_{t+1|t+1} &= P_{t+1|t} - P_{t+1|t}C\trans\left(CP_{t+1|t}C\trans + \Sigma_{v}\right)^{-1}CP_{t+1|t}
%\end{align}

\subsection{Kalman Filter Equations For Non-Linear System }
Now we consider a nonlinear extension to the Kalman filter, \textbf{Extended Kalman Filters (EKF)}. The EKF implements a Kalman filter for a non-linear system dynamics that results from the linearization of the original non-linear filter dynamics around the previous state estimates.

A non linear system can be represented as follows.
\begin{align}
x_{k} &= f\left(x_{k-1},u_{k-1}\right)+w_{k-1} \notag \\
z_{k} &= h\left(x_{k}\right) + v_{k-1}
\label{eqn:nonlinearsystem}
\end{align}
where $w_{k} \sim N\left(0,Q_k\right)$ and  $v_{k} \sim
N\left(0,R_k\right)$.

We will proceed with the assumption that f(), h(), Q and R are time invariant for our non linear system.
f() and h() are  linearized about the prior best estimates of the states at each instant of time by finite difference method as,in order to compute covariance.
Given initial state estimate, $\hat{x}_{0|0}$ and initial state covariance matrix, $\Sigma_{0|0}$ the Extended Filter can be computed using following set of equations.


\subsubsection{Prediction or Time update:}
\begin{align}
\hat{x}_{k|k-1} &=  f\left(\hat{x}_{k-1|k-1},u_{k-1}\right) \notag\\
\Sigma_{k|k-1} &= J_f \Sigma_{k-1|k-1} J_f^T + Q 
\label{eqn:predictionnonLinear}
\end{align}

\subsubsection{Innovation or Measurement update:}
\begin{align}
H_k &=  \Sigma_{k|k-1} J_h^T {(J_h \Sigma_{k|k-1} J_h^T + R)}^{-1}\notag\\
\hat{x}_{k|k} &=  \hat{x}_{k|k-1} + H_k [z_{k} - h\left(\hat{x}_{k|k-1}\right)]\notag\\
\Sigma_{k|k} &= [I - H_kJ_h]\Sigma_{k|k-1}
\label{eqn:innovationnonLinear}
\end{align}

where $J_f$ and $J_h$ are the jacobians.

$J_f$ is the jacobian matrix with the partial derivatives of the system function f($\cdot$ , $\cdot$) with respect to the state x, evaluated at the last state estimate $\hat{x}_{k-1|k-1}$ and control input $u_{k-1}$.

$J_h$ is the jacobian matrix with partial derivatives of the measurement
function h(.) with respect to the state x, evaluated at the prior state
estimate $\hat{x}_{k|k-1}$.


\subsection{Extended Kalman Filter Equations For Odometry}
 
 After deriving model of our system for odometry \ref{s:10-odometry--finaleq} and understanding the extended kalman Filter in previous section, we will now prepare the extended kalman filter equations for odometry.
 
 \begin{IEEEeqnarray}{CCCCCCCCC} \label{eq:KFxk + noise function}
 	\begin{bmatrix}
 		x_{[x],k}\\
 		x_{[y],k}\\
 		x_{[\theta],k}\\
 	\end{bmatrix}
 	 & = & 
 	\begin{bmatrix}
 		f_x(x_{k-1}, u_{k-1})\\
 		f_y(x_{k-1}, u_{k-1})\\
 		f_\theta(x_{k-1}, u_{k-1})\\
 	\end{bmatrix}
 	& + &
 	\begin{bmatrix}
 		w_{[x],k-1})\\
 		w_{[y],k-1})\\
 		w_{[\theta],k-1})\\
 	\end{bmatrix}	
 \end{IEEEeqnarray} 
 
  \begin{IEEEeqnarray}{CCCCCCCCC} \label{eq:KFSysEq}
  	\begin{bmatrix}
  		x_{[x],k}\\
  		x_{[y],k}\\
  		x_{[\theta],k}\\
  	\end{bmatrix}
  	& = & 
  	\begin{bmatrix}
  		x_{[x],k-1} + u_{[\Delta] S,k-1} \cdot \cos(x_{[\Theta],k-1} - \frac{u_{[\Delta\Theta],k-1}}{2}) \\
  		x_{[y],k-1} + u_{[\Delta] S,k-1} \cdot \sin(x_{[\Theta],k-1} - \frac{u_{[\Delta\Theta],k-1}}{2}) \\
  		x_{[\theta],k-1} - u_{[\Delta\Theta],k-1})\\
  	\end{bmatrix}
  	& + &
  	\begin{bmatrix}
  		w_{[x],k-1})\\
  		w_{[y],k-1})\\
  		w_{[\theta],k-1})\\
  	\end{bmatrix}	
  \end{IEEEeqnarray} 


\subsubsection{Prediction or Time update:}

  \begin{IEEEeqnarray}{CCCCC} \label{eq:KFprediction1Odometry}
  	\begin{bmatrix}
  		\hat{x}_{[x],k|k-1}\\
  		\hat{x}_{[y],k|k-1}\\
  		\hat{x}_{[\theta],k|k-1}\\
  	\end{bmatrix}
  	& = & 
  	\begin{bmatrix}
  		\hat{x}_{[x],k-1|k-1} + u_{[\Delta] S,k-1} \cdot \cos(\hat{x}_{[\Theta],k-1|k-1} - \frac{u_{[\Delta\Theta],k-1}}{2}) \\
  		\hat{x}_{[y],k-1} + u_{[\Delta] S,k-1} \cdot \sin(\hat{x}_{[\Theta],k-1|k-1} - \frac{u_{[\Delta\Theta],k-1}}{2}) \\
  		\hat{x}_{[\theta],k-1|k-1} - u_{[\Delta\Theta],k-1})\\
  	\end{bmatrix}
  \end{IEEEeqnarray} 


\begin{align}
J_{f,k}  &=  \frac{\partial f(x)}{\partial x}\Bigr|_{x = \hat{x}_{k-1|k-1}, u = u_{k-1}} \notag\\
&=  	\begin{bmatrix}
\frac{\partial f_x}{\partial x_{[x]}} & \frac{\partial f_x}{\partial x_{[y]}} & \frac{\partial f_x}{\partial x_{[\theta]}}\\
\frac{\partial f_y}{\partial x_{[x]}} & \frac{\partial f_y}{\partial x_{[y]}} & \frac{\partial f_y}{\partial x_{[\theta]}}\\
\frac{\partial f_\theta}{\partial x_{[x]}} & \frac{\partial f_\theta}{\partial x_{[y]}} & \frac{\partial f_\theta}{\partial x_{[\theta]}}\\
\end{bmatrix}_{x = \hat{x}_{k-1|k-1}, u = u_{k-1}} \notag\\
&=  	\begin{bmatrix}
1 & 0 & - u_{[\Delta] S} \cdot \sin(x_{[\Theta]} - \frac{u_{[\Delta\Theta]}}{2})\\
0 & 1 & + u_{[\Delta] S} \cdot \cos(x_{[\Theta]} - \frac{u_{[\Delta\Theta]}}{2}) \\
0 & 0 & 1\\
\end{bmatrix}_{x = \hat{x}_{k-1|k-1}, u = u_{k-1}} \notag\\
\label{eqn:JacobfOdometry}
\end{align}

\begin{align}
%\hat{x}_{k|k-1} &=  f\left(\hat{x}_{k-1|k-1},u_{k-1}\right) \notag\\
\Sigma_{[x],k|k-1} &= J_f \Sigma_{[x],k-1|k-1} J_f^T + Q 
\label{eqn:predictionOdometry}
\end{align}

%where $\Sigma_{[x]}$ is a 3x3 state covariance matrix and $Q$ is a 3x3 process covariance matrix.

%
%\begin{IEEEeqnarray}{CCCCC} \label{eq:KFprediction2Odometry}
%	\begin{bmatrix}
%		\Sigma_{[x][x],k|k-1} & \Sigma_{[x][y],k|k-1} & \Sigma_{[x][\theta],k|k-1} \\
%		\Sigma_{[y][x],k|k-1} & \Sigma_{[y][y],k|k-1} & \Sigma_{[y][\theta],k|k-1} \\
%		\Sigma_{[\theta][x],k|k-1} & \Sigma_{[\theta][x],k|k-1} & \Sigma_{[\theta][\theta],k|k-1} \\
%	\end{bmatrix}
%	& = & 
%	\begin{bmatrix}
%		1 & 0 & - u_{[\Delta] S} \cdot \sin(x_{[\Theta]} - \frac{u_{[\Delta\Theta]}}{2})\\
%		0 & 1 & + u_{[\Delta] S} \cdot \cos(x_{[\Theta]} - \frac{u_{[\Delta\Theta]}}{2}) \\
%		0 & 0 & 1\\
%	\end{bmatrix}_{x = \hat{x}_{k-1|k-1}, u = u_{k-1}} \notag\\
%	\begin{bmatrix}
%			\Sigma_{[x][x],k|k-1} & \Sigma_{[x][y],k|k-1} & \Sigma_{[x][\theta],k|k-1} \\
%			\Sigma_{[y][x],k|k-1} & \Sigma_{[y][y],k|k-1} & \Sigma_{[y][\theta],k|k-1} \\
%			\Sigma_{[\theta][x],k|k-1} & \Sigma_{[\theta][x],k|k-1} & \Sigma_{[\theta][\theta],k|k-1} \\
%	\end{bmatrix}
%		\begin{bmatrix}
%			1 & 0 & - u_{[\Delta] S} \cdot \sin(x_{[\Theta]} - \frac{u_{[\Delta\Theta]}}{2})\\
%			0 & 1 & + u_{[\Delta] S} \cdot \cos(x_{[\Theta]} - \frac{u_{[\Delta\Theta]}}{2}) \\
%			0 & 0 & 1\\
%		\end{bmatrix}^T_{x = \hat{x}_{k-1|k-1}, u = u_{k-1}} \notag\\
%%	J_f \Sigma_{[x],k-1|k-1} J_f^T 
%	& + &
%	\begin{bmatrix}
%			{\sigma}^2_{w[x],k} & 0 &  0\\
%			0 & {\sigma}^2_{w[y],k} & 0\\
%			0 & 0 & {\sigma}^2_{w[\theta],k}\\
%	\end{bmatrix} 
%\end{IEEEeqnarray} 


\subsubsection{Innovation or Measurement update:}
\begin{align}
J_{h,k}  &=  \frac{\partial h(x)}{\partial x}\Bigr|_{x = \hat{x}_{k|k-1}} \notag\\
	&=  	\begin{bmatrix}
	\frac{\partial h_x}{\partial x_{[x]}} & \frac{\partial h_x}{\partial x_{[y]}} & \frac{\partial h_x}{\partial x_{[\theta]}}\\
	\frac{\partial h_y}{\partial x_{[x]}} & \frac{\partial h_y}{\partial x_{[y]}} & \frac{\partial h_y}{\partial x_{[\theta]}}\\
	\frac{\partial h_\theta}{\partial x_{[x]}} & \frac{\partial h_\theta}{\partial x_{[y]}} & \frac{\partial h_\theta}{\partial x_{[\theta]}}\\
	\end{bmatrix}_{x = \hat{x}_{k|k-1}, u = u_{k-1}} \notag\\
	&=  	\begin{bmatrix}
	1 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 1\\
	\end{bmatrix}_{x = \hat{x}_{k|k-1}, u = u_{k-1}} \notag\\
	\label{eqn:JacobhOdometry}
\end{align}

Using the above derived jacobian matrix \eref{eqn:JacobhOdometry} for computation of Kalman gain matrix, $H_k$, aposteriori state estimate and aposteriori error covariance matrix, we get following equations.

\begin{align}
H_k &=  \Sigma_{k|k-1}  {( \Sigma_{k|k-1} + R)}^{-1}\notag\\
\hat{x}_{k|k} &=  \hat{x}_{k|k-1} + H_k [z_{k} - \hat{x}_{k|k-1}]\notag\\
\Sigma_{k|k} &= [I - H_kJ_h]\Sigma_{k|k-1}
\label{eqn:innovationnonLinearmodel}
\end{align}


\subsection{Practical Implementation of EKF}

Proceeding with the EKF model for odometry, we need initializing of the model before we can practically implement it. We need to initialize following components.
\begin{enumerate}
	\item Initial state estimate, $\hat{x}_{0|0}$ 
	\item Initial state covariance matrix, $\Sigma_{0|0}$
	\item Process covariance matrix, Q
	\item Measurement covariance matrix, R
\end{enumerate}


\subsubsection{ Initial state estimate, $\hat{x}_{0|0}$ }
This is the initial estimate of the state vector required for the first iteration of the EKF. 
In our system, Optitrack motion capture system is used for measurement. Optitrack provides ground truth and positional accuracy of up to sub-millimeter. 
For our testing, we simply used the measurement sensor reading to determine  $\hat{x}_{0|0}$.

\subsubsection{ Initial state covariance matrix, $\Sigma_{0|0}$}
Initial state covariance matrix is based on the initialization error of the state. If the initial state estimate is very close to the actual state, this matrix will contain very small values. With the assumption that noise sources for different state elements are independent, the off diagonal elements of the covariance matrix can be taken to be zero.

Usually if this matrix is unknown, we can use identity matrix since this matrix is updated in every iteration of EKF. For a stable EKF, this matrix should be converging.
A better initial estimate will offer faster convergence of the Kalman filter.

For our testing, since we determine the initial state from the measurement sensor, initial state covariance matrix can be taken as zero. However, since we are simulating a sensor not as accurate as motion capture, the matrix is taken as identity.

\subsubsection{ Process covariance matrix, Q}
This is the error covariance matrix of the process and gives an estimate of uncertainty in the state equations. The uncertainty in the process could be in result of various sources of error include modeling errors, odometry errors, discretization, approximations involved in the derivation of the model.

In order to get a feel of error in the model, we computed error based on odometry model from log files.
%and could understand not much about it

For testing, we tried different range of values for Q to understand the behaviour of the EKF.  


\subsubsection{ Measurement covariance matrix, R}
This is the error covariance matrix of measurement sensor and gives a measure of how uncertain is measurement. As discussed earlier, Optitrack motion capture system is used for measurement and it provides ground truth. 
For the case when the measurement is very accurate, matrix R will carry very small variances and can be zero. However, in order to simulate EKF for a system whose measurement sensor is not as accurate, we tried different range of values for covariance matrix.



\subsection{ Divergence of state covariance matrix, $\Sigma_{k|k}$}

Proceeding with initialization of EKF as discussed above, it was observed that the filter behaved well for some time after initialization. However, after some time the state covariance matrix started diverging very fast, resulting in failure of the Filter. 

It was understood that a possible reason behind this could be lack of input excitation that results in growing values of state covariance matrix and large spread of eigen values. In order to cater this issue, different techniques can be used to stabilize estimation and prevent windup of state estimation and covariance matrix.
 
We resolved this issue by performing Cholesky decompostion in the computation of Kalman gain matrix.  Cholesky factorization is a decomposition of a Hermitian, positive-definite matrix into the product of a lower triangular matrix (or an upper triangular matrix)and its conjugate transpose. Cholesky decomposition offers numerical stability to the system.

This resulted in good behavior of the filter, however, it slowed down the performance of EKF. With Cholesky decomposition, the innovation update of EKF can be written as shown in \eref{eqn:choleskynonLinear}

\begin{align}
U &= CholsekyDecomposition (J_h \Sigma_{k|k-1} J_h^T + R)\notag\\
\hat{x}_{k|k} &=  \hat{x}_{k|k-1} +  [\Sigma_{k|k-1} {U}^{-1}]{U^T}^{-1} [z_{k} - h\left(\hat{x}_{k|k-1}\right)]\notag\\
\Sigma_{k|k} &= \Sigma_{k|k-1} - [\Sigma_{k|k-1} {U}^{-1}][\Sigma_{k|k-1} {U}^{-1}]^T
\label{eqn:choleskynonLinear}
\end{align}

where $CholsekyDecomposition (X)$ produces an upper triangular matrix $U$ from the diagonal and upper triangle of matrix $X$, satisfying the equation $U^T*U=X$.
%
%R=chol(Jh*P12+R)            %Cholesky factorization
%U=P12*inv(R)                    %K=U/R'; Faster because of back substitution
%x_cc = x_cp + U*(inv(R')*(z-z_estimate))         %Back substitution to get state update
%E_cc = E_cp - U*U'                   %Covariance update, U*U'=P12/R/R'*P12'=K*P12.

\subsection{ROS documentation}

Robot Operating System (ROS) is a collection of software frameworks for robot software development, it works as middleware for work with complex robotic problems. It uses the publisher subscriber software architecture model for nodes. The presented problem of localization of a humanoid robot using extended Kalman filter, which has been described in detail in previous section [ref section], has been solved using ROS.
[Number of nodes] nodes have been developed respecting the aspects of modularity and exchangebility of software:
\begin{itemize}
	\item Preprocessor node
	\item Control node
	\item Communication node
	\item Extended Kalman filter node
	\item Visualization
	\item [Analysis]
\end{itemize}

Each node is supposed to fulfill one function, however there are several aspects that have been merged into nodes, that might be contraintuitive. Functionalities of the nodes are distributed the following way:
\begin{enumerate}
	\item Preprocessor node:
	\item Control node:
	\begin{enumerate}
		\item Translate input from keyboard into linear and angular velocities within unitary limits ($-100\% \div 100\%$)
		\item Publish data
	\end{enumerate}
	\item Communication node:
	\begin{enumerate}
		\item Translate data from control node into a 3 byte message for Rollo
		\item Send data continuosly at a given rate to Rollo
		\item Perform emergency procedure if connection to control node is lost
		\item [fix number, A for previous options, B for this one]
		\item Square test of n-th order
		\begin{enumerate}
			\item Perform a cycle of forward movement and turn
			\item For higher than 1 order square test, turn around between runs
		\end{enumerate}
	\end{enumerate}
	\item Extented Kalman filter node:
	\begin{enumerate}
		\item Preprocessing of acquired data to make comparison of relevant information
		\item Estimate of state using EKF
		\item Odometry data calculation
		\item Publish results
	\end{enumerate}
	\item Visualization node:
	\begin{enumerate}
		\item Visualize data from preprocessor and extended Kalman filter, which provides estimates of state and odometry data
	\end{enumerate}
\end{enumerate}

Nodes have been written in C++ with the exception of visualization node, which is written in Python, because of easy access to the powerful Matplotlib [reference] library. There has been also a significant amount of testing and prototyping of software done in Matlab and Python, mainly for the odometry model and extended Kalman filter implementation and analysis. Additional scripts in Bash shell were also written, mostly for the purpose of easier repetition of tasks.

The basic software architecture model implemented is publish-subscribe given the architecture ROS uses represented by [reference to diagram].

More in depth documentation of the actual code and algorithms has been done using Doxygen in two formats: html version [reference to github] and local document form [reference to refman.pdf]. Only the most important points shall be described here.

A few aspects have been addressed while developing the software. One of those aspects is safety of operation. Should the control node loose connection to the master and at the same time be sending other than full stop (linear and angular velocities equal to zero), then in normal case the communication node would continue sending data with last values received from control node. This is the reason a safety or emergency procedure has been implemented, so that after a period of time, which can be specified from the command line, a full stop command is being send for 10 [verify] times. Should the control node reestablish connection, the communication node will continue to work in normal procedure. Since the robot has been tested in laboratory conditions, the algorithm implemented is not very robust and could be further improved. For example, the stop command could be send conitnuosly, until control node is reconnected with ROS master or forcefully exited. Another improvement would be to send a special message that this event occured, so that the user is informed about it without delay.

Next feature implemented into the communication node is the square test. In this particular test [provide more description] [provide reference]. The implemented algorithm lets the user specify the forward and turning times for the square test, which is necessary in case of not having access to odometry data. The square test can be performed in multiple runs, so that each cycle includes:

\begin{enumerate}
	\item Moving forward
	\item Turning $90\deg$
	\item Moving forward
	\item Turning $90\deg$
	\item Moving forward
	\item Turning $90\deg$
	\item Moving forward
	\item Turning $90\deg$
\end{enumerate}

Should there be multiple runs specified, the robot would turn around, which is to rotate $180\deg$ and continue with step 1. It other case that would be the last run, ideally the robot would stop at exactly the same position it started with the initial orientation. Since there are systematic and random errors, this is only achieveable for a given tolerance.

During tests runs it has been only confirmed, what the analysis of the logs performed for the extended Kalman filter node concluded, namely that the turning times differ significantly, which is most probably due to mechanical asymmetry. This makes the source code for this particular robot somewhat irrelevant. However it has been decided to leave the current implementation at this state, since it actually is sound from the theoretical point of view and most robots should have the similar turning speeds for both directions.


% % % % CODE REFERENCE
%
%\scalefig{test.jpg}{0.8}{test66}\label{img:img1}
%
%\section{Epipolar geometry}
%\label{s:2}
%\indent\indent
%asd \ref{f:test.jpg} dsa
%
%\begin{enumerate}
%	\item Epipole: Projection of optical centers of the cameras lenses $O$, into the other camera image plane:
%	\begin{enumerate}
%		\item Left epipole: Projection of $O_R$ on the left image plane $e_L$.
%		\item Right epipole: Projection of $O_L$ on the right image plane $e_R$.
%	\end{enumerate}
%	\item Baseline: Line connecting $O_L$ and $O_R$. The baseline intersects each image plane at the epipoles $e_L$ and $e_R$.
%	\item Epipolar plane: Plane containing 3 points in space $X$, $O_L$ and $O_R$.
%	\item Epipolar line: Intersection of the epipolar plane with the image plane.
%\end{enumerate}
%
%The line $O_L\!\--\!X$ is seen by left camera as a point, because it is directly in line with that cameraâ€™s centre of projection. This means all the points on this line e.g. $X$, $X_1$, $X_2$, $X_3$ will be projected on $x_L$. However, the right camera sees this line as an actual line in its image plane. The projection of this line is in fact an epipolar line. In the same manner, line $O_R\!\--\!X$ is projected on the epipolar line $x_L\!\--\!e_L$ on the left image plane. 
%
%\begin{equation}\label{e:2}
%	p_r^T F p_l = 0
%\end{equation}
%
%where 
%
%\begin{IEEEeqnarray}{CCCCCCCCC} \label{e:3}
%	p_r & = & 
%	\begin{bmatrix}
%		x_r \\
%		y_r \\
%		1
%	\end{bmatrix} ,  & \phantom{~ ~} & & \phantom{~ ~} &
%	p_l & = & 
%	\begin{bmatrix}
%		x_l \\
%		y_l \\
%		1
%	\end{bmatrix}
%\end{IEEEeqnarray}
%
%If fundamental matrix F is written as shown in \bref{eq:4}
%
%\begin{IEEEeqnarray}{CCCCC} \label{e:4}
%	F & = & 
%	\begin{bmatrix}
%		 f_{11}	& f_{12} & f_{13}\\
%		 f_{21}	& f_{22} & f_{23}\\
%		 f_{31} & f_{32} & f_{33}\\
%	\end{bmatrix},
%\end{IEEEeqnarray}
%
%equation \bref{eq:2} can be rewritten to the from portrayed by equation \bref{eq:5}
%
%asd \ref{f:test.jpg} dsa
%
%\begin{equation} \label{e:5}
%	x_l x_r f_{11} + x_l y_r f_{21} + x_l f_{31} + y_l x_r f_{12} + y_l y_r f_{22} + y_l f_{32} + x_r f_{13} + y_r f_{23} + f_{33} = 0
%\end{equation}
%
%The entries of the fundamental matrix F, can be determined by establishing eight or more correspondences. The equation \bref{eq:5} is rearranged to form a homogeneous system, as shown in \bref{eq:6}.
%
%\begin{equation} \label{e:6}
%A f = 0
%\end{equation}
%
%\begin{IEEEeqnarray}{CCCCCCCCCCCCCCC} \label{e:7}
%	A & = & 
%	\begin{bmatrix}
%		x_{l1} x_{r1}	& x_{l1} y_{r1} &  x_{l1} & y_{l1} x_{r1} & y_{l1} y_{r1} & y_{l1} & x_{r1} & y_{r1} & 1 \\
%		x_{l2} x_{r2}	& x_{l2} y_{r2} &  x_{l2} & y_{l2} x_{r2} & y_{l2} y_{r2} & y_{l2} & x_{r2} & y_{r2} & 1 \\
%		\vdots & \vdots & \vdots & \vdots & \vdots &  \vdots & \vdots & \vdots &  \\
%		x_{ln} x_{rn}	& x_{ln} y_{rn} &  x_{ln} & y_{ln} x_{rn} & y_{ln} y_{rn} & y_{ln} & x_{rn} & y_{rn} & 1 \\
%	\end{bmatrix}
%\end{IEEEeqnarray}
%
%\begin{IEEEeqnarray}{CCCCCCCCC} \label{e:8}
%	f & = & 
%	\begin{bmatrix}
%		f_{11}\\
%		f_{12}\\
%		f_{13}\\
%		f_{21}\\
%		f_{22}\\
%		f_{23}\\
%		f_{31}\\
%		f_{32}\\
%		f_{33}\\
%	\end{bmatrix}
%\end{IEEEeqnarray}
%
%%- We can determine the entries of the matrix F (up to an unknown scale factor) by
%%establishing n Â³ 8 correspondences:
%%Ax = 0
%%- It turns out that A is rank deficient (i.e., $rank(A) = 8$); the solution is unique up to a scale factor (i.e., proportional to the last column of $V$ where $A = U D V T$ ).
%
%Matrix $A$ is $n \verb|x| 9$ matrix where $n$ is the number of correspondences. However, the rank of matrix $A$ is $8$, which makes it rank deficient. This gives a unique solution up to a scale factor and the solution is proportional to the last column of $V$, where $A = U D V^T $.
%
%The 8-point algorithm can be summarised in following steps.
%
%\begin{enumerate}
%	\item Take $n$ correspondences from $2$ stereo pair images where $n$ is greater than $8$.
%	\item Construct homogeneous system $Ax = 0$, as described above, where $A$ is an $n \verb|x| 9$ matrix.
%	\item Matrix $F$ can be computed by singular value decomposition (SVD) of matrix $A$. The entries of $F$ are proportional to the components of the last column of $V$.
%	\item Enforce the [singularity] constraint: $rank(F) = 2$ by the following steps:
%	\begin{enumerate}
%		\item Compute the SVD of $F$.
%		\item Set the smallest singular value equal to $0$ and let $D$ be the corrected matrix.
%		\item The corrected estimate of $F$ is given by $F_{e} = U D V^T$.
%	\end{enumerate}
%\end{enumerate}
%
%
%\section{Point normalization}
%\label{s:pointnormalization}
%
%In order to implement the 8-point algorithm and estimate the fundamental matrix $F$, corresponding points in the image are expressed in a vector form of 3 elements, as shown in equations \bref{eq:3} and \bref{eq:4}. The $3^{rd}$ element of the vector is assigned the value of $1$ and this is done to prepare a homogeneous vector. For most of the corresponding points, the first two elements are much larger than the $3^{rd}$ element. However, this results in vector pointing in more or less the same direction for all points. Similarly, the $F$ estimated with this approach is not invariant to point transformations.
%
%In order to make the algorithm numerically stable and the estimation more precise, it is more suitable to use normalized points. This is done by transforming the coordinates of each of the two images independently such that the \textit{average} point is equal to $(1, 1, 1)^T$, which is achieved in 2 steps:
%
%\begin{enumerate}
%	\item The origin of the new coordinate system is centered (has its origin) at the centroid (center of gravity) of the image points. This is accomplished by a translation of the original origin to the new one. 
%	\item After the translation, the coordinates are uniformly scaled, so that their average distance from the origin equals $\sqrt{2}$.
%\end{enumerate}
%
%This principle results in a distinct coordinate transformation for each of the two images. As a result, new homogeneous image coordinates $p_l$, $p_r$, are given by
%
%\begin{equation}\label{e:10}
%\bar{p}_l =  T_l p_l 
%\end{equation}
%\begin{equation}\label{e:11}
%\bar{p}_r =  T_r p_r 
%\end{equation}
%
%where $T_l$, $T_r$ are the normalized transformations, responsible for translation and scaling from the old to the new normalized image coordinates. This normalization is only dependent on the image points, which are used in a single image. Normalized transformation is given by equation \bref{eq:9}
%
%\begin{IEEEeqnarray}{CCCCC}\label{e:9}
%	T & = & 
%	\begin{bmatrix}
%		s & 0 & -sc_x \\
%		0 & s & -sc_y \\
%		0 & 0 & 1 \\
%	\end{bmatrix}
%\end{IEEEeqnarray}
%
%where $c$ is the centroid of all points and $s$ is the scale to make average distance equal to $\sqrt{2}$.
%
%This normalization should be carried out before applying the 8-point algorithm. After the fundamental matrix $\bar{F}$ has been estimated, de-normalization is done to get the results in original coordinates system. $\bar{F}$ can be de-normalized to give $F$ according to \bref{eq:12}.
%
%\begin{equation}\label{e:12}
%F = T_r^T \bar{F} T_l
%\end{equation}
%
%In general, this estimate of the fundamental matrix is a more precise one, than one would have obtained by estimating from not normalized coordinates, even at the price of a few calculations more.
%
%% This normalizing transformation will nullify the eï¬€ect of the arbitrary selection of origin and scale in the coordinate frame of the image, and will mean that the combined algorithm is invariant to a similarity transformation of the image.
%
%\clearpage
%
%\section{Main script}
%\label{s:mainscript}
%%\lstinputlisting[language=Matlab, firstline=1, firstnumber=1]{L06.m}
%\noindent\noindent
%%\script{L06}{Script calling the implemented 8-point algorithm for two image sets with and without normalization of points.}
%
%\begin{equation}\label{e:epipoles}
%F = U W V^T
%\end{equation}
%
%Additionally an epipolar check has been conducted, which should also result in $0$ in the ideal case, as displayed by equations (\ref{eq:epc1} $\div$ \ref{eq:epci2}). The algorithm of performing the test and printing the results (lines $125 \div 149$) is analogue to that of epipolar constraint check, with the difference that each point set is used with its corresponding epipole. Worth mentioning is the actual value of the tolerance used for this check. For the given image sets, $\epsilon$ can be as low as $\epsilon = 10^{-12}$.
%
%\begin{equation}\label{e:epc1}
%e_L^T F P_1 < \epsilon
%\end{equation}
%\begin{equation}\label{e:epc2}
%e_R^T F^T P_2 < \epsilon
%\end{equation}
%
%\begin{equation}\label{e:epci1}
%e_L^T F x_L = 0
%\end{equation}
%\begin{equation}\label{e:epci2}
%e_R^T F^T x_R = 0
%\end{equation}

%\movie[externalviewer]{abc}{test.mp4}
%\movie[width=4cm, height=3cm, poster, externalviewer]{abc}{test.mp4}

%\includemedia[width=4cm, height=3cm, addresource=test.mp4, flashvars={source=test.mp4}]{}{test.mp4}

%\begin{center}
%	\href{run:mpv test.mp4}{
%		\includegraphics[scale=0.25]
%		{test.jpg}}
%\end{center}

% % % % CODE REFERENCE

\section{Conclusions}
\indent\indent


%\end{Section}
\end{Problem}
%\layout
\end{spacing}
\end{document}


% % % Licence

%----------------------------------------------------------------------%
% The following is copyright and licensing information for
% redistribution of this LaTeX source code; it also includes a liability
% statement. If this source code is not being redistributed to others,
% it may be omitted. It has no effect on the function of the above code.
%----------------------------------------------------------------------%
% Copyright (c) 2007, 2008, 2009, 2010, 2011 by Theodore P. Pavlic
%
% Unless otherwise expressly stated, this work is licensed under the
% Creative Commons Attribution-Noncommercial 3.0 United States License. To
% view a copy of this license, visit
% http://creativecommons.org/licenses/by-nc/3.0/us/ or send a letter to
% Creative Commons, 171 Second Street, Suite 300, San Francisco,
% California, 94105, USA.
%
% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
% OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
% MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
% IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
% CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
% TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
% SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
%----------------------------------------------------------------------%